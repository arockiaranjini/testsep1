{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVbwUFAfYAFr6AI2gCIUhT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arockiaranjini/testsep1/blob/main/1_week_6_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Lmg9eWZAFoR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('/content/sample_data/names.txt','r').read().splitlines()\n",
        "words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv2Sz4avAmBe",
        "outputId": "fe470d48-3fa6-4fe5-9a4d-070706c2cdbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ6f2P4lAXpb",
        "outputId": "2b74fa59-6bde-4a3d-ad2a-1b54f8e6f807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-F1akaAOdPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e49975-eae3-4119-d2b3-d65c361d6e7d",
        "id": "XwONFj72Odk6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CajzMrQOPmb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e706070-ef67-48d3-c30a-db499b10de1c",
        "id": "6hKp1bARPmw9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5cBRhSzBd7k",
        "outputId": "8a02c3a2-94a2-466b-fd29-5eaefc5fae9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "X, Y = [], []\n",
        "# w -->letter in words\n",
        "for w in words[:5]:\n",
        "    print(w)\n",
        "    #[0]--> .\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "        context = context[1:] + [ix] # crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zFj5Qm6BjHp",
        "outputId": "26d47403-c5a6-4f09-e8d5-837d5bd82cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2KzohC-BoAs",
        "outputId": "0c371110-f99a-4dd2-ad5f-07788e5739e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwi7I4eVBujY",
        "outputId": "edd966a6-bcf4-4ebe-8e86-ad5a38e8f49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0,  5],\n",
              "        [ 0,  5, 13],\n",
              "        [ 5, 13, 13],\n",
              "        [13, 13,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 15],\n",
              "        [ 0, 15, 12],\n",
              "        [15, 12,  9],\n",
              "        [12,  9, 22],\n",
              "        [ 9, 22,  9],\n",
              "        [22,  9,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  1],\n",
              "        [ 0,  1, 22],\n",
              "        [ 1, 22,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  9],\n",
              "        [ 0,  9, 19],\n",
              "        [ 9, 19,  1],\n",
              "        [19,  1,  2],\n",
              "        [ 1,  2,  5],\n",
              "        [ 2,  5, 12],\n",
              "        [ 5, 12, 12],\n",
              "        [12, 12,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 19],\n",
              "        [ 0, 19, 15],\n",
              "        [19, 15, 16],\n",
              "        [15, 16,  8],\n",
              "        [16,  8,  9],\n",
              "        [ 8,  9,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRJKos23Bvqt",
        "outputId": "28a6bca1-9896-4bb9-bf1f-ea567734665b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn(27,2)"
      ],
      "metadata": {
        "id": "Bcuc0SuseIeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAxWYkbueaD7",
        "outputId": "68421b91-9d85-4c55-869e-98bf1a449daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5985,  0.6246],\n",
              "        [ 0.4146,  0.1480],\n",
              "        [ 0.5193, -0.6891],\n",
              "        [ 0.9772,  0.6164],\n",
              "        [-0.1702,  1.7808],\n",
              "        [ 0.9569,  1.2902],\n",
              "        [-0.1899,  0.7296],\n",
              "        [-0.1294, -0.6790],\n",
              "        [ 0.8862,  0.4332],\n",
              "        [-0.3611, -1.2462],\n",
              "        [ 1.1567,  0.2232],\n",
              "        [ 2.3348,  1.5768],\n",
              "        [ 0.2252,  0.7303],\n",
              "        [-0.7958, -0.7593],\n",
              "        [ 0.0949,  0.9927],\n",
              "        [-0.3943,  0.4676],\n",
              "        [ 0.3658, -0.8441],\n",
              "        [ 1.2469, -1.0275],\n",
              "        [ 0.7224, -0.7977],\n",
              "        [ 0.5345,  1.1042],\n",
              "        [ 0.7009,  0.4909],\n",
              "        [ 0.6348,  0.3719],\n",
              "        [-0.8936, -2.1128],\n",
              "        [-0.1074, -0.4924],\n",
              "        [ 1.2452, -0.8715],\n",
              "        [ 0.6264, -0.5913],\n",
              "        [-0.3354,  0.9229]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LuUrsHced_Q",
        "outputId": "2e3890ff-d84f-46cc-8f80-743de90082d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6nRPlZ3emCK",
        "outputId": "b43d2578-baf3-4a3e-c473-b1a97400ddec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9569, 1.2902])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(torch.tensor(5),num_classes = 27)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxDD4pege5Uj",
        "outputId": "2f80bf85-c9be-44ca-aa43-47d52e47be5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdnPrE-ifTBl",
        "outputId": "1a6316d4-4852-4dfe-dad6-04d1aba58ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [ 0.9569,  1.2902]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [ 0.9569,  1.2902],\n",
              "         [-0.7958, -0.7593]],\n",
              "\n",
              "        [[ 0.9569,  1.2902],\n",
              "         [-0.7958, -0.7593],\n",
              "         [-0.7958, -0.7593]],\n",
              "\n",
              "        [[-0.7958, -0.7593],\n",
              "         [-0.7958, -0.7593],\n",
              "         [ 0.4146,  0.1480]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [-0.3943,  0.4676]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.3943,  0.4676],\n",
              "         [ 0.2252,  0.7303]],\n",
              "\n",
              "        [[-0.3943,  0.4676],\n",
              "         [ 0.2252,  0.7303],\n",
              "         [-0.3611, -1.2462]],\n",
              "\n",
              "        [[ 0.2252,  0.7303],\n",
              "         [-0.3611, -1.2462],\n",
              "         [-0.8936, -2.1128]],\n",
              "\n",
              "        [[-0.3611, -1.2462],\n",
              "         [-0.8936, -2.1128],\n",
              "         [-0.3611, -1.2462]],\n",
              "\n",
              "        [[-0.8936, -2.1128],\n",
              "         [-0.3611, -1.2462],\n",
              "         [ 0.4146,  0.1480]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [ 0.4146,  0.1480]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [ 0.4146,  0.1480],\n",
              "         [-0.8936, -2.1128]],\n",
              "\n",
              "        [[ 0.4146,  0.1480],\n",
              "         [-0.8936, -2.1128],\n",
              "         [ 0.4146,  0.1480]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [-0.3611, -1.2462]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.3611, -1.2462],\n",
              "         [ 0.5345,  1.1042]],\n",
              "\n",
              "        [[-0.3611, -1.2462],\n",
              "         [ 0.5345,  1.1042],\n",
              "         [ 0.4146,  0.1480]],\n",
              "\n",
              "        [[ 0.5345,  1.1042],\n",
              "         [ 0.4146,  0.1480],\n",
              "         [ 0.5193, -0.6891]],\n",
              "\n",
              "        [[ 0.4146,  0.1480],\n",
              "         [ 0.5193, -0.6891],\n",
              "         [ 0.9569,  1.2902]],\n",
              "\n",
              "        [[ 0.5193, -0.6891],\n",
              "         [ 0.9569,  1.2902],\n",
              "         [ 0.2252,  0.7303]],\n",
              "\n",
              "        [[ 0.9569,  1.2902],\n",
              "         [ 0.2252,  0.7303],\n",
              "         [ 0.2252,  0.7303]],\n",
              "\n",
              "        [[ 0.2252,  0.7303],\n",
              "         [ 0.2252,  0.7303],\n",
              "         [ 0.4146,  0.1480]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [-0.5985,  0.6246],\n",
              "         [ 0.5345,  1.1042]],\n",
              "\n",
              "        [[-0.5985,  0.6246],\n",
              "         [ 0.5345,  1.1042],\n",
              "         [-0.3943,  0.4676]],\n",
              "\n",
              "        [[ 0.5345,  1.1042],\n",
              "         [-0.3943,  0.4676],\n",
              "         [ 0.3658, -0.8441]],\n",
              "\n",
              "        [[-0.3943,  0.4676],\n",
              "         [ 0.3658, -0.8441],\n",
              "         [ 0.8862,  0.4332]],\n",
              "\n",
              "        [[ 0.3658, -0.8441],\n",
              "         [ 0.8862,  0.4332],\n",
              "         [-0.3611, -1.2462]],\n",
              "\n",
              "        [[ 0.8862,  0.4332],\n",
              "         [-0.3611, -1.2462],\n",
              "         [ 0.4146,  0.1480]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative\n",
        "F.one_hot(torch.tensor(5),num_classes = 27).float() @ C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgENMZyLe7iA",
        "outputId": "af75b8ce-c452-44ee-e5d6-dfd954fa79ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9569, 1.2902])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP6TjVtBgix1",
        "outputId": "557fe166-d4da-4b60-a101-ddd2acd0d04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hidden layer\n",
        "W1 = torch.randn(6,100)\n",
        "b1 = torch.randn(100)\n",
        "# emb @ W1 + b1\n",
        "# emb [32, 3, 2]  W1 [6, 100]\n",
        "# [32, 100]\n"
      ],
      "metadata": {
        "id": "-ybId6Cmiemr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USucFTbsWCPk",
        "outputId": "dcfceba9-e65a-462f-db29-bebc24f2d9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.8183e-02,  4.9524e-01,  3.4335e-01,  1.6447e+00, -2.5268e-01,\n",
              "          8.7134e-01, -8.3944e-01, -1.1137e+00, -2.7489e-01,  8.7768e-01,\n",
              "         -1.7843e+00, -9.7738e-01,  2.5496e-01,  8.3042e-01, -1.3230e-01,\n",
              "          3.7143e-01, -2.4177e-01,  8.1824e-02,  4.6145e-01,  1.1175e+00,\n",
              "          1.1049e+00, -5.8938e-01,  1.4568e+00, -1.1017e+00,  1.7952e-01,\n",
              "          1.0330e+00,  7.5859e-02,  5.2718e-01,  1.8077e+00,  2.7793e-01,\n",
              "          1.3723e+00,  1.3244e+00, -1.1392e+00,  5.5220e-01, -1.5035e+00,\n",
              "          1.8417e-01,  3.9946e-01, -3.5051e-01, -1.1690e+00, -1.0676e+00,\n",
              "          1.6748e+00,  3.9256e-01,  1.7526e-01, -6.9495e-01,  4.2871e-01,\n",
              "          1.1950e+00, -6.7204e-01, -1.6967e+00,  1.4218e+00,  1.0965e+00,\n",
              "         -1.3164e+00,  3.1407e+00,  1.8581e+00,  8.7314e-01,  7.1773e-01,\n",
              "          8.8150e-02,  7.4445e-01,  2.3654e+00,  5.5907e-02,  6.2556e-01,\n",
              "         -3.7078e-01, -1.5716e+00, -9.2361e-01,  1.3199e-01,  3.9186e-01,\n",
              "          2.0015e-01,  1.9470e+00, -7.6841e-01,  2.3944e-01, -1.6401e+00,\n",
              "          6.0626e-02,  1.1387e+00,  3.8453e-01, -2.1487e+00,  9.7544e-01,\n",
              "          1.0333e-01,  1.2297e+00,  3.7621e-01, -1.7641e+00, -4.8818e-01,\n",
              "         -1.5428e-01,  5.2345e-01,  3.1239e-01,  4.8456e-01,  1.3081e-01,\n",
              "          1.6506e+00, -6.3757e-01, -1.5699e+00, -9.8096e-01, -1.2848e-01,\n",
              "         -2.2352e-01, -2.0646e+00,  8.6247e-01,  1.2134e-01, -4.1417e-01,\n",
              "         -8.0317e-01, -3.7565e-01,  1.4148e+00,  2.7734e-01,  8.8778e-01],\n",
              "        [ 1.1188e+00, -7.4369e-01,  1.5893e+00,  3.9901e-01,  9.0898e-01,\n",
              "         -7.4762e-02, -9.9368e-01, -1.7097e+00,  1.1647e+00, -2.2849e+00,\n",
              "          1.1003e+00,  1.2504e+00, -3.6181e-04,  2.2094e+00, -1.0511e+00,\n",
              "          7.1480e-01, -5.9999e-01,  8.5587e-01,  7.2441e-01, -1.7011e+00,\n",
              "          7.2517e-01,  9.2592e-01,  7.3758e-01,  5.7492e-02,  5.1046e-01,\n",
              "         -1.9172e+00,  3.4864e-01, -8.4600e-01,  1.5265e+00, -7.6034e-02,\n",
              "         -5.6824e-01, -1.0153e+00,  1.8745e+00, -1.5520e+00,  4.3181e-01,\n",
              "         -7.0247e-01,  2.7498e-01, -8.3457e-01, -3.8187e-01,  1.0460e+00,\n",
              "         -1.3713e-01,  7.6339e-01,  3.9128e-02,  1.2036e+00,  7.0618e-01,\n",
              "         -1.3394e+00,  1.1138e-01,  9.4111e-01,  1.2250e+00,  1.5443e-01,\n",
              "         -7.0064e-01,  5.9042e-01,  5.4997e-01,  1.1200e+00, -3.1232e-01,\n",
              "         -1.5745e+00, -7.8084e-01, -1.0566e+00, -8.2648e-01,  6.8625e-01,\n",
              "          4.5932e-02, -7.2090e-01, -1.8664e-01,  8.8960e-01,  1.6783e+00,\n",
              "          8.4749e-01,  4.6537e-01, -9.2267e-01,  3.0705e-01,  1.4489e+00,\n",
              "         -3.8411e-01,  6.9914e-01, -3.5045e-01,  1.3749e-01,  1.7585e-02,\n",
              "         -1.6446e+00,  1.4026e+00, -9.8866e-01, -1.0705e+00, -6.4920e-02,\n",
              "          3.5010e-01, -6.5124e-01,  6.5136e-02, -8.5731e-01,  2.8306e-02,\n",
              "         -9.9445e-01,  9.6414e-01, -1.0544e+00, -7.1950e-01, -9.2023e-01,\n",
              "          2.8667e+00,  1.7529e-01, -1.4141e+00, -5.2593e-02,  2.7240e+00,\n",
              "          1.6531e+00, -1.5636e+00,  2.4511e-01, -1.7843e-01, -9.8839e-01],\n",
              "        [ 1.1680e+00, -6.8919e-01,  4.4367e-01, -6.6322e-01, -7.0589e-01,\n",
              "         -1.7800e-01,  1.2565e+00, -5.0615e-01,  8.4796e-01, -8.8310e-01,\n",
              "          1.3539e+00, -7.9221e-01, -1.7777e+00,  4.2019e-01, -8.1957e-01,\n",
              "         -1.3169e+00, -1.9150e+00,  1.1543e-01,  3.5644e-01,  4.5631e-01,\n",
              "         -1.3392e+00,  5.4035e-01,  8.9092e-01, -5.4180e-01,  1.5744e+00,\n",
              "         -1.3331e+00,  7.5195e-01,  3.6431e-01, -1.1319e-01,  1.5054e+00,\n",
              "         -1.5302e+00, -1.9157e-01, -6.7833e-01,  7.3978e-01,  1.2864e+00,\n",
              "         -4.8894e-01,  4.0726e-01, -1.9235e+00,  9.4168e-01,  6.0532e-01,\n",
              "          3.0644e-01, -1.4885e-01,  7.1411e-01, -1.9568e-01, -8.5558e-01,\n",
              "         -1.2077e+00, -1.1199e+00, -6.2005e-01,  2.0710e-01,  4.3372e-01,\n",
              "         -2.9718e-01, -1.6537e-01, -2.5328e-01,  1.4483e+00,  1.4410e+00,\n",
              "          9.8367e-01,  1.6245e+00,  1.2844e+00,  1.3079e+00, -4.7655e-01,\n",
              "         -1.5700e+00, -7.6419e-01, -2.0595e+00,  1.3924e+00,  4.2107e-01,\n",
              "         -4.0061e-01, -1.1124e+00,  1.6809e+00,  8.0274e-01, -8.2432e-01,\n",
              "         -3.6561e-01,  1.2681e+00, -8.8949e-01, -1.2727e+00,  7.7207e-01,\n",
              "         -4.4715e-01,  4.1915e-01, -1.7297e+00,  1.4374e-01, -1.3852e+00,\n",
              "         -3.8679e-01,  2.7149e-01, -1.0205e-01,  1.2959e+00,  5.8159e-02,\n",
              "          1.8617e+00, -1.3548e+00,  4.0474e-01, -1.0536e+00,  3.6135e-01,\n",
              "         -8.3402e-01,  5.4912e-01, -3.4313e-02,  3.9698e-01, -6.3704e-02,\n",
              "         -4.5319e-02, -3.1255e-01,  6.8716e-01, -7.6613e-01, -1.3300e+00],\n",
              "        [-7.6412e-01,  1.0155e+00, -1.6969e+00,  3.8096e-01, -6.4837e-01,\n",
              "          1.0245e+00, -2.1388e-01,  2.9555e-01,  5.4251e-01,  7.0046e-01,\n",
              "          6.0524e-01,  5.9803e-01, -8.1447e-01, -4.5490e-01,  1.7992e+00,\n",
              "         -1.2920e-01, -2.6763e-02,  2.5044e-01, -1.3222e+00,  1.3975e+00,\n",
              "          1.4264e+00, -5.0673e-01, -1.3347e+00, -1.1766e+00,  1.7492e+00,\n",
              "          1.3004e+00, -6.5769e-01,  1.3427e+00, -1.6918e-01,  2.8416e-01,\n",
              "         -9.6480e-01, -2.8321e-02,  2.2569e+00,  7.2566e-01, -1.4929e+00,\n",
              "         -1.3542e+00,  1.4501e+00, -6.1201e-01,  1.0655e-01,  5.0311e-01,\n",
              "         -3.1990e-01,  1.6414e-01,  2.0204e-01, -4.8565e-01, -7.9934e-01,\n",
              "          2.3874e-01, -6.9852e-02,  5.7489e-01,  2.5796e-01,  9.0328e-01,\n",
              "         -5.8144e-02, -1.1829e+00,  8.3664e-01,  1.2220e+00, -1.3099e+00,\n",
              "          5.0491e-01,  1.8685e+00,  6.3915e-01,  1.1817e+00,  1.5340e+00,\n",
              "          1.2334e+00,  1.1739e+00,  1.0916e+00,  3.6686e-01,  6.0662e-01,\n",
              "          4.6632e-01, -4.5573e-01,  5.2291e-01, -6.4089e-01,  4.5450e-02,\n",
              "         -5.0052e-01,  1.8945e-01, -2.9407e-04,  1.7420e+00, -3.4424e-01,\n",
              "         -1.7379e-01, -8.6485e-01, -5.1837e-01,  8.3514e-01, -7.1775e-01,\n",
              "          1.5016e-01, -6.8458e-01, -2.8134e-01, -3.1103e-01, -1.1268e+00,\n",
              "         -2.9802e-01,  1.4638e+00, -1.7992e-01, -2.1925e+00, -2.5618e+00,\n",
              "          1.0740e+00, -7.7946e-01, -9.1981e-01, -6.0269e-01,  1.3185e+00,\n",
              "          4.5786e-01, -2.9573e-01, -6.9238e-02,  7.5561e-01, -2.6966e+00],\n",
              "        [ 1.2787e+00, -9.2174e-01,  3.9886e-01, -7.3786e-01, -7.2605e-01,\n",
              "          4.6380e-01, -7.7260e-01,  4.6405e-01,  8.8146e-01, -2.4754e+00,\n",
              "          5.4043e-02,  8.8203e-01, -9.3158e-01, -6.1990e-01,  9.6073e-01,\n",
              "          6.9177e-01, -2.3887e-01,  5.7823e-01, -2.7562e-01, -1.2437e+00,\n",
              "         -1.2541e-01,  5.7486e-01,  1.5387e+00,  2.0634e-01, -4.3568e-01,\n",
              "          1.0939e+00,  5.5503e-01,  7.7744e-01,  1.8896e+00,  8.2792e-01,\n",
              "         -1.8462e+00,  1.8454e-01, -6.8528e-01, -3.8742e-01,  1.2283e-01,\n",
              "         -4.6550e-01, -6.7460e-01, -9.4966e-01, -1.0289e+00, -1.3965e+00,\n",
              "         -1.6514e+00, -6.9971e-01,  1.1554e+00, -2.5964e+00,  5.0883e-01,\n",
              "         -4.0332e-01, -3.1400e-01, -2.8484e-01,  1.1618e+00,  6.5751e-01,\n",
              "          1.4354e+00,  3.5640e-01, -7.9099e-01, -1.2691e+00,  1.1069e+00,\n",
              "          7.6588e-01, -1.8906e+00, -8.8953e-01,  2.8253e-01, -1.2651e+00,\n",
              "          1.4914e+00,  1.1692e+00, -6.1295e-01,  5.0572e-01, -1.3359e+00,\n",
              "         -6.6888e-01, -3.1034e-01, -2.2809e-01, -1.5398e+00, -5.9089e-02,\n",
              "          9.0269e-02,  3.7897e-01, -7.1880e-01,  2.5363e-01, -6.6271e-01,\n",
              "          8.9716e-01,  9.8662e-01,  6.9505e-01, -1.1874e+00,  1.5229e-02,\n",
              "          1.5382e-01, -1.1227e+00,  4.2201e-01,  6.2010e-01,  3.8996e-01,\n",
              "          1.5215e+00, -3.3191e-01,  4.2325e-02, -1.2075e-01, -7.2870e-01,\n",
              "          2.9853e-01,  6.7633e-01,  1.8670e+00, -4.6130e-01, -7.6199e-01,\n",
              "          7.7565e-01, -2.9597e+00, -1.0304e+00, -4.8598e-01, -6.5820e-01],\n",
              "        [-2.7163e-02,  1.0559e+00, -9.1005e-02,  2.9660e-01, -3.6415e-01,\n",
              "          1.0591e+00, -2.0400e+00, -1.1266e+00,  4.1076e-01,  8.9923e-01,\n",
              "         -2.3004e+00, -1.0065e+00, -9.7721e-01,  2.0546e+00, -2.9912e-01,\n",
              "         -2.3407e+00, -1.0633e+00, -1.0425e+00,  2.5252e-01,  2.9360e-01,\n",
              "          7.5524e-01,  5.8608e-01,  1.4200e+00, -1.7590e+00, -3.8682e-01,\n",
              "         -1.8512e-01,  5.5418e-01,  3.2196e-01,  1.1613e+00,  1.0938e+00,\n",
              "          3.5606e-01, -1.0025e+00,  1.0818e+00, -9.2926e-01, -1.7607e-01,\n",
              "          3.2057e-01, -9.4187e-01, -1.3531e+00,  9.8170e-01,  1.6638e-01,\n",
              "         -7.4224e-01,  8.6441e-01,  2.4827e-01,  2.4749e-01, -8.3471e-01,\n",
              "         -5.6568e-01,  2.0409e-01, -9.5451e-01,  6.6376e-01, -1.4472e+00,\n",
              "         -1.1176e+00, -2.5285e-01, -3.2128e-02,  1.3181e+00, -7.2791e-01,\n",
              "         -4.2257e-01,  3.0373e-01,  1.3408e+00, -5.1806e-01, -2.9657e+00,\n",
              "         -5.7007e-01,  1.3796e+00, -4.1540e-01, -8.5392e-01, -9.6937e-01,\n",
              "         -1.5626e-02, -3.0013e-01, -1.3043e+00,  1.0615e-01,  7.5347e-02,\n",
              "          1.3743e+00,  1.5222e+00,  1.1146e+00,  1.5838e-02,  1.6691e-01,\n",
              "          7.2340e-01,  8.2792e-01, -8.2433e-01,  1.0959e+00, -8.4220e-01,\n",
              "         -2.4457e+00,  5.2685e-01,  4.2617e-01, -1.1364e-01,  1.6393e+00,\n",
              "          4.8616e-02, -2.5898e-01, -5.1054e-01,  1.1569e+00, -2.8548e-02,\n",
              "          1.1976e+00,  3.1016e-02,  1.4364e+00, -6.9790e-01,  7.2067e-01,\n",
              "          1.0033e+00,  1.2972e+00,  1.8657e-01,  1.1194e-02,  1.4464e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ILtuRtriv91",
        "outputId": "e38577ff-6bac-497c-9267-bafea278bb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5985,  0.6246, -0.5985,  0.6246, -0.5985,  0.6246],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246,  0.9569,  1.2902],\n",
              "        [-0.5985,  0.6246,  0.9569,  1.2902, -0.7958, -0.7593],\n",
              "        [ 0.9569,  1.2902, -0.7958, -0.7593, -0.7958, -0.7593],\n",
              "        [-0.7958, -0.7593, -0.7958, -0.7593,  0.4146,  0.1480],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246, -0.5985,  0.6246],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246, -0.3943,  0.4676],\n",
              "        [-0.5985,  0.6246, -0.3943,  0.4676,  0.2252,  0.7303],\n",
              "        [-0.3943,  0.4676,  0.2252,  0.7303, -0.3611, -1.2462],\n",
              "        [ 0.2252,  0.7303, -0.3611, -1.2462, -0.8936, -2.1128],\n",
              "        [-0.3611, -1.2462, -0.8936, -2.1128, -0.3611, -1.2462],\n",
              "        [-0.8936, -2.1128, -0.3611, -1.2462,  0.4146,  0.1480],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246, -0.5985,  0.6246],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246,  0.4146,  0.1480],\n",
              "        [-0.5985,  0.6246,  0.4146,  0.1480, -0.8936, -2.1128],\n",
              "        [ 0.4146,  0.1480, -0.8936, -2.1128,  0.4146,  0.1480],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246, -0.5985,  0.6246],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246, -0.3611, -1.2462],\n",
              "        [-0.5985,  0.6246, -0.3611, -1.2462,  0.5345,  1.1042],\n",
              "        [-0.3611, -1.2462,  0.5345,  1.1042,  0.4146,  0.1480],\n",
              "        [ 0.5345,  1.1042,  0.4146,  0.1480,  0.5193, -0.6891],\n",
              "        [ 0.4146,  0.1480,  0.5193, -0.6891,  0.9569,  1.2902],\n",
              "        [ 0.5193, -0.6891,  0.9569,  1.2902,  0.2252,  0.7303],\n",
              "        [ 0.9569,  1.2902,  0.2252,  0.7303,  0.2252,  0.7303],\n",
              "        [ 0.2252,  0.7303,  0.2252,  0.7303,  0.4146,  0.1480],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246, -0.5985,  0.6246],\n",
              "        [-0.5985,  0.6246, -0.5985,  0.6246,  0.5345,  1.1042],\n",
              "        [-0.5985,  0.6246,  0.5345,  1.1042, -0.3943,  0.4676],\n",
              "        [ 0.5345,  1.1042, -0.3943,  0.4676,  0.3658, -0.8441],\n",
              "        [-0.3943,  0.4676,  0.3658, -0.8441,  0.8862,  0.4332],\n",
              "        [ 0.3658, -0.8441,  0.8862,  0.4332, -0.3611, -1.2462],\n",
              "        [ 0.8862,  0.4332, -0.3611, -1.2462,  0.4146,  0.1480]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 32,3,2 [-1 = 32]\n",
        "h = emb.view(-1,6) @ W1 + b1"
      ],
      "metadata": {
        "id": "YjZe7vdMi05Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hidden layer\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qm8cfgLi6xc",
        "outputId": "96932fde-f99e-4913-c209-4c3a29cefb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "CFI47Ofti-mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipa2L4TAlRzl",
        "outputId": "3b535d70-3479-4fb1-ea34-50cd78e93cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9665,  0.1956, -0.8048,  ...,  0.5782,  0.9062, -0.6752],\n",
              "        [-0.0653, -0.4874, -0.5023,  ..., -0.6743,  0.6397, -0.7071],\n",
              "        [-0.7365, -0.9009, -0.9059,  ...,  0.9257,  0.7152, -1.0000],\n",
              "        ...,\n",
              "        [ 0.9579, -0.9973,  0.9775,  ...,  0.1087, -0.7537,  0.7352],\n",
              "        [-0.9120, -0.9280, -0.9533,  ...,  0.9707,  0.5492, -0.9931],\n",
              "        [ 0.5505, -0.9845,  0.9929,  ...,  0.9539, -0.1402,  0.9994]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn(100,27)\n",
        "b2 = torch.randn(27)\n",
        "# h [32,100] W2 [100,27]\n",
        "# [32,27]"
      ],
      "metadata": {
        "id": "p3-oAUJ5li2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okuwlBkzlwDC",
        "outputId": "e6cd4bb5-ee5d-4ea2-b0b0-0506fb5d5ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1949,  1.7443,  0.6253,  ..., -1.5217, -1.8561,  0.3264],\n",
              "        [ 0.3400,  0.9418, -0.0156,  ..., -1.4391, -0.0625,  0.0973],\n",
              "        [-0.3136,  1.3849, -0.8615,  ...,  0.6549, -1.0142,  0.2038],\n",
              "        ...,\n",
              "        [ 1.4555,  0.8391,  0.7304,  ..., -0.8179, -0.8094,  0.6668],\n",
              "        [ 1.1748,  0.2525, -1.1924,  ...,  0.8433,  1.4883,  0.5350],\n",
              "        [ 0.8498,  1.6799,  0.7824,  ...,  0.8423,  2.8687,  0.4672]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 + b2"
      ],
      "metadata": {
        "id": "2yWIqsnBljlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_LFGUlki955",
        "outputId": "71e49a28-b6df-4992-ec71-3609fc1918cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.5589,  0.1688,  1.5206,  ...,  2.3221, -1.5223,  0.4649],\n",
              "        [-1.7308,  0.7441,  0.2569,  ..., -1.0727, -3.7110,  0.9398],\n",
              "        [-2.3198,  0.0481, -2.3803,  ..., -0.0709, -2.7397, -0.6533],\n",
              "        ...,\n",
              "        [-2.8118,  0.4140,  4.2234,  ...,  1.8294, -1.1517,  4.5967],\n",
              "        [-2.6613,  0.1783,  1.0845,  ...,  1.3633, -5.7019,  1.1010],\n",
              "        [ 3.7866, -0.8394,  1.2126,  ...,  4.9823,  1.0392,  0.8883]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aONS5o_l97z",
        "outputId": "5c3a1eb5-aed9-4294-98df-33bb6d6c7bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-HBJdwmBTS",
        "outputId": "aee23367-4d6a-4068-e7f3-3919dc4c204f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  9.5322,   0.0505,   4.9023, -11.6165, -12.6236,   7.9809,   0.6413,\n",
              "          6.9113,   3.7647,  -1.5330,   5.9128,  -5.7028,   0.8669, -10.0738,\n",
              "         -3.1963,   0.7728,   5.3305,  -8.0342,   5.1006,  -4.3876,   1.2677,\n",
              "         -4.4247,  11.4761,  -0.0978,   1.3778, -11.2789,  -4.5994])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob = logits.exp() / logits.exp().sum(1, keepdims = True)"
      ],
      "metadata": {
        "id": "cjI7mDwomL2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-104d1omi7n",
        "outputId": "d8aeb928-347a-4988-bad2-674d2c7c2bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1993e-01, 9.1425e-06, 1.1699e-03, 7.8371e-11, 2.8627e-11, 2.5420e-02,\n",
              "        1.6505e-05, 8.7227e-03, 3.7508e-04, 1.8766e-06, 3.2138e-03, 2.9004e-08,\n",
              "        2.0683e-05, 3.6655e-10, 3.5563e-07, 1.8826e-05, 1.7953e-03, 2.8177e-09,\n",
              "        1.4266e-03, 1.0805e-07, 3.0879e-05, 1.0411e-07, 8.3781e-01, 7.8822e-06,\n",
              "        3.4476e-05, 1.0984e-10, 8.7422e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob[1].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0dd4iSYmNLG",
        "outputId": "7206eda7-1c87-4837-eec9-e63cfc4df14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP-ry7AamWvR",
        "outputId": "254e2c3c-916f-4572-fff1-f6d4455be0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1993e-01, 9.1425e-06, 1.1699e-03, 7.8371e-11, 2.8627e-11, 2.5420e-02,\n",
              "         1.6505e-05, 8.7227e-03, 3.7508e-04, 1.8766e-06, 3.2138e-03, 2.9004e-08,\n",
              "         2.0683e-05, 3.6655e-10, 3.5563e-07, 1.8826e-05, 1.7953e-03, 2.8177e-09,\n",
              "         1.4266e-03, 1.0805e-07, 3.0879e-05, 1.0411e-07, 8.3781e-01, 7.8822e-06,\n",
              "         3.4476e-05, 1.0984e-10, 8.7422e-08],\n",
              "        [2.2796e-01, 1.1147e-08, 7.9202e-04, 5.9417e-07, 3.2427e-06, 1.1127e-04,\n",
              "         2.7088e-04, 5.3273e-06, 8.9858e-04, 9.9334e-06, 7.3833e-01, 1.7596e-07,\n",
              "         1.3613e-05, 2.6097e-13, 2.0725e-05, 6.1041e-09, 5.1622e-10, 2.5497e-05,\n",
              "         5.0666e-03, 2.8994e-11, 3.1385e-05, 2.2053e-09, 2.6178e-02, 2.5831e-04,\n",
              "         8.2250e-09, 5.7807e-09, 2.8066e-05],\n",
              "        [1.6890e-03, 2.6506e-10, 2.7981e-08, 6.1133e-11, 4.7243e-03, 4.5906e-09,\n",
              "         5.6345e-04, 2.9523e-04, 1.3969e-04, 6.9642e-05, 3.5882e-03, 2.0967e-08,\n",
              "         4.7074e-08, 1.0202e-04, 2.5502e-03, 1.6577e-07, 6.0530e-03, 1.3328e-09,\n",
              "         8.9628e-01, 1.5790e-03, 8.8963e-07, 1.9827e-03, 7.9036e-02, 2.1985e-04,\n",
              "         7.3822e-05, 6.2552e-04, 4.2284e-04],\n",
              "        [1.0538e-03, 7.8527e-08, 1.1346e-04, 1.4822e-07, 9.8273e-16, 2.5999e-03,\n",
              "         1.1231e-04, 3.8188e-06, 3.7429e-12, 3.7913e-04, 7.6064e-09, 2.3365e-09,\n",
              "         2.6135e-09, 1.9945e-10, 2.8895e-03, 2.5981e-01, 8.6921e-05, 4.2761e-08,\n",
              "         1.9846e-08, 1.7922e-06, 1.0242e-08, 9.2877e-07, 7.3204e-01, 5.5444e-08,\n",
              "         5.1332e-08, 1.7767e-08, 9.1247e-04],\n",
              "        [2.1250e-12, 9.3982e-08, 1.1871e-02, 2.6537e-04, 4.8355e-08, 3.7124e-01,\n",
              "         1.5238e-03, 1.3687e-05, 6.1394e-09, 4.0885e-08, 9.1320e-06, 1.1010e-08,\n",
              "         6.1451e-01, 9.4850e-12, 1.8313e-12, 1.0603e-05, 4.0229e-04, 1.8072e-09,\n",
              "         1.4595e-10, 1.2179e-10, 1.0585e-07, 3.0812e-13, 1.4461e-04, 8.3172e-08,\n",
              "         7.9036e-12, 9.2409e-10, 9.1728e-06],\n",
              "        [1.1993e-01, 9.1425e-06, 1.1699e-03, 7.8371e-11, 2.8627e-11, 2.5420e-02,\n",
              "         1.6505e-05, 8.7227e-03, 3.7508e-04, 1.8766e-06, 3.2138e-03, 2.9004e-08,\n",
              "         2.0683e-05, 3.6655e-10, 3.5563e-07, 1.8826e-05, 1.7953e-03, 2.8177e-09,\n",
              "         1.4266e-03, 1.0805e-07, 3.0879e-05, 1.0411e-07, 8.3781e-01, 7.8822e-06,\n",
              "         3.4476e-05, 1.0984e-10, 8.7422e-08],\n",
              "        [7.4239e-02, 1.7775e-06, 3.0642e-03, 7.6733e-11, 1.0969e-10, 1.2969e-02,\n",
              "         7.9075e-05, 1.9456e-02, 7.3036e-04, 2.7482e-06, 5.6292e-03, 4.2086e-08,\n",
              "         7.5376e-05, 1.5160e-10, 5.4409e-07, 3.6148e-05, 1.5940e-03, 4.3912e-09,\n",
              "         9.2399e-04, 1.6429e-07, 3.8021e-04, 2.2064e-07, 8.8076e-01, 2.8755e-05,\n",
              "         3.2287e-05, 1.0602e-10, 1.8634e-06],\n",
              "        [8.4052e-01, 5.1067e-08, 5.0265e-03, 9.2984e-09, 9.0267e-09, 2.8005e-04,\n",
              "         9.7737e-05, 1.0945e-03, 8.3141e-06, 5.0993e-05, 9.7260e-02, 1.0816e-06,\n",
              "         5.6704e-06, 4.6449e-13, 3.0730e-06, 2.2950e-06, 3.6651e-07, 1.2584e-07,\n",
              "         5.0264e-02, 4.6542e-09, 8.1438e-04, 3.3313e-08, 4.5399e-03, 1.9030e-05,\n",
              "         3.7466e-06, 5.6649e-10, 4.7078e-06],\n",
              "        [6.0119e-07, 7.8922e-13, 5.6649e-09, 1.5812e-13, 1.1920e-06, 2.5472e-08,\n",
              "         6.4653e-06, 2.2688e-03, 9.6468e-06, 2.8197e-08, 2.0014e-05, 1.0408e-11,\n",
              "         9.5702e-06, 2.3570e-04, 1.1389e-06, 1.8484e-08, 1.8451e-03, 2.7626e-11,\n",
              "         2.7414e-05, 1.2958e-04, 1.5700e-06, 2.7283e-06, 9.9372e-01, 7.9445e-09,\n",
              "         1.0382e-05, 1.5305e-08, 1.7065e-03],\n",
              "        [3.5814e-12, 1.6821e-05, 7.1634e-09, 7.7937e-14, 1.0888e-14, 1.8765e-04,\n",
              "         6.7348e-05, 1.2682e-02, 1.3598e-14, 4.9808e-08, 1.8200e-08, 6.2513e-09,\n",
              "         7.4763e-08, 7.8474e-04, 5.6504e-07, 2.5027e-02, 4.9928e-01, 1.3515e-08,\n",
              "         7.1313e-12, 6.9404e-03, 1.7838e-07, 4.5662e-08, 6.5403e-04, 1.7142e-08,\n",
              "         2.2197e-11, 1.4562e-08, 4.5436e-01],\n",
              "        [6.1708e-16, 6.4269e-06, 1.1700e-09, 7.6290e-06, 1.9615e-11, 9.6749e-01,\n",
              "         2.4749e-03, 1.1025e-03, 4.3821e-16, 8.6665e-15, 3.8480e-06, 3.4825e-09,\n",
              "         4.8236e-07, 1.7918e-04, 5.3142e-13, 1.2072e-06, 2.6752e-02, 2.4928e-07,\n",
              "         8.6012e-11, 1.4286e-06, 4.3017e-10, 6.1494e-11, 1.2776e-08, 1.2450e-11,\n",
              "         9.5507e-13, 3.9712e-05, 1.9447e-03],\n",
              "        [2.3799e-15, 4.7162e-04, 4.5054e-03, 4.6770e-04, 1.1135e-06, 1.6179e-01,\n",
              "         2.0414e-02, 1.1334e-08, 4.8700e-09, 1.5265e-11, 1.6170e-06, 2.4802e-07,\n",
              "         8.1131e-01, 1.0226e-08, 4.4123e-13, 3.2528e-10, 1.0295e-03, 1.2370e-06,\n",
              "         1.2529e-08, 9.3125e-11, 5.3771e-07, 2.2013e-10, 1.3051e-08, 8.7808e-10,\n",
              "         5.9563e-12, 5.9877e-06, 1.9392e-08],\n",
              "        [1.1993e-01, 9.1425e-06, 1.1699e-03, 7.8371e-11, 2.8627e-11, 2.5420e-02,\n",
              "         1.6505e-05, 8.7227e-03, 3.7508e-04, 1.8766e-06, 3.2138e-03, 2.9004e-08,\n",
              "         2.0683e-05, 3.6655e-10, 3.5563e-07, 1.8826e-05, 1.7953e-03, 2.8177e-09,\n",
              "         1.4266e-03, 1.0805e-07, 3.0879e-05, 1.0411e-07, 8.3781e-01, 7.8822e-06,\n",
              "         3.4476e-05, 1.0984e-10, 8.7422e-08],\n",
              "        [1.1015e-02, 3.8596e-10, 2.2995e-02, 3.5019e-10, 2.5591e-07, 1.7028e-04,\n",
              "         7.4318e-04, 5.5648e-02, 9.5808e-04, 7.5797e-06, 9.8781e-02, 1.7134e-08,\n",
              "         1.6265e-04, 8.8681e-12, 3.8921e-07, 1.2363e-06, 9.1999e-05, 1.5329e-10,\n",
              "         8.2895e-05, 1.6954e-07, 2.7193e-01, 9.8347e-06, 5.3728e-01, 2.4422e-06,\n",
              "         3.0650e-07, 2.4489e-09, 1.1648e-04],\n",
              "        [4.8804e-12, 1.5516e-12, 8.5417e-13, 2.2422e-17, 1.5131e-08, 9.8297e-09,\n",
              "         9.0346e-09, 2.5972e-01, 2.4537e-10, 2.9413e-08, 7.9445e-09, 9.7822e-12,\n",
              "         2.7223e-07, 7.3072e-01, 2.1012e-06, 2.9518e-09, 4.8356e-04, 1.8335e-12,\n",
              "         4.0109e-06, 8.1782e-03, 2.2585e-11, 1.1582e-08, 8.4406e-05, 1.9741e-09,\n",
              "         7.0908e-09, 1.3814e-10, 8.1128e-04],\n",
              "        [4.7916e-06, 1.1436e-06, 6.6698e-04, 1.8789e-04, 1.0301e-12, 2.4469e-01,\n",
              "         4.6856e-05, 1.3151e-06, 4.2251e-15, 8.8508e-06, 8.8418e-09, 1.2825e-05,\n",
              "         2.8215e-07, 4.1432e-12, 1.3158e-07, 1.7270e-05, 8.2250e-05, 7.3489e-01,\n",
              "         4.4201e-10, 3.4803e-09, 3.2053e-06, 1.1329e-08, 1.1152e-03, 1.2770e-09,\n",
              "         3.8384e-11, 4.2847e-09, 1.8276e-02],\n",
              "        [1.1993e-01, 9.1425e-06, 1.1699e-03, 7.8371e-11, 2.8627e-11, 2.5420e-02,\n",
              "         1.6505e-05, 8.7227e-03, 3.7508e-04, 1.8766e-06, 3.2138e-03, 2.9004e-08,\n",
              "         2.0683e-05, 3.6655e-10, 3.5563e-07, 1.8826e-05, 1.7953e-03, 2.8177e-09,\n",
              "         1.4266e-03, 1.0805e-07, 3.0879e-05, 1.0411e-07, 8.3781e-01, 7.8822e-06,\n",
              "         3.4476e-05, 1.0984e-10, 8.7422e-08],\n",
              "        [3.0800e-09, 4.9018e-13, 4.9620e-10, 1.9728e-13, 2.8401e-09, 1.9824e-07,\n",
              "         5.5494e-05, 1.3744e-03, 4.1001e-06, 1.5957e-07, 6.5440e-06, 1.0665e-12,\n",
              "         1.5261e-03, 2.5460e-06, 2.4902e-07, 4.7442e-06, 3.2657e-03, 1.4162e-12,\n",
              "         5.9119e-10, 2.8884e-07, 8.3283e-06, 9.0223e-10, 9.8131e-01, 1.9323e-09,\n",
              "         7.4976e-08, 9.3679e-12, 1.2438e-02],\n",
              "        [4.2706e-03, 5.8920e-05, 3.0167e-02, 6.1244e-05, 4.3453e-10, 8.7531e-01,\n",
              "         1.8951e-02, 1.2446e-03, 1.8580e-10, 1.8470e-03, 8.7821e-07, 2.8589e-03,\n",
              "         2.0051e-06, 2.9279e-15, 2.2196e-07, 2.0848e-06, 5.7330e-08, 2.7527e-04,\n",
              "         1.4378e-03, 8.4160e-12, 6.3672e-07, 3.3744e-07, 5.5651e-03, 5.7729e-02,\n",
              "         1.0927e-10, 5.2180e-08, 2.2113e-04],\n",
              "        [1.8062e-04, 4.7311e-09, 4.8498e-03, 3.5017e-06, 8.2609e-01, 1.6254e-10,\n",
              "         3.0087e-06, 9.9460e-10, 8.4251e-02, 2.6983e-11, 4.8195e-07, 1.9301e-07,\n",
              "         8.6647e-03, 2.7460e-09, 2.3389e-09, 7.3910e-12, 6.8674e-02, 6.8466e-10,\n",
              "         6.7967e-03, 1.6455e-07, 6.4319e-06, 3.3351e-08, 4.7963e-04, 1.0830e-10,\n",
              "         6.9410e-11, 8.5136e-07, 2.3569e-09],\n",
              "        [1.1108e-01, 2.9757e-08, 2.0645e-01, 7.0601e-10, 3.2281e-07, 5.6223e-09,\n",
              "         5.6823e-06, 6.7404e-06, 1.4491e-09, 8.4122e-05, 3.2029e-08, 1.6955e-07,\n",
              "         1.5936e-10, 3.0661e-04, 4.6133e-04, 8.1690e-05, 6.3634e-04, 3.5368e-01,\n",
              "         7.8817e-02, 9.9547e-05, 3.5053e-03, 3.4529e-03, 1.6845e-01, 3.3925e-09,\n",
              "         4.0115e-07, 6.7274e-07, 7.2866e-02],\n",
              "        [1.1352e-03, 4.0036e-06, 1.1130e-06, 2.3975e-06, 7.7767e-09, 3.3826e-13,\n",
              "         4.6906e-08, 3.7236e-12, 8.4485e-14, 2.3851e-10, 1.5547e-13, 1.0555e-05,\n",
              "         1.1571e-12, 6.1322e-15, 1.7713e-10, 1.0799e-11, 1.0837e-13, 9.9879e-01,\n",
              "         4.9784e-05, 1.7480e-11, 1.4067e-06, 1.9688e-07, 1.3215e-07, 3.3006e-07,\n",
              "         3.6282e-13, 2.3335e-09, 1.1689e-06],\n",
              "        [1.9230e-01, 3.4666e-10, 1.3070e-03, 2.0095e-08, 5.5099e-03, 5.0040e-13,\n",
              "         1.2724e-05, 8.5958e-14, 4.6285e-01, 3.1943e-10, 1.7635e-09, 1.0155e-07,\n",
              "         1.0129e-06, 2.3551e-14, 2.8876e-05, 7.9960e-13, 3.0022e-06, 1.4361e-07,\n",
              "         2.1560e-01, 5.4259e-06, 2.3496e-03, 1.1289e-08, 1.2003e-01, 4.3197e-10,\n",
              "         2.8130e-07, 1.1479e-06, 1.4165e-09],\n",
              "        [9.9994e-01, 9.1994e-14, 1.7167e-05, 1.2344e-09, 2.0860e-12, 3.3864e-15,\n",
              "         2.4664e-08, 1.1543e-11, 2.8370e-10, 3.0890e-05, 3.9966e-12, 6.3643e-09,\n",
              "         2.8442e-13, 3.4492e-17, 3.1624e-07, 7.2358e-09, 1.3745e-10, 5.2034e-06,\n",
              "         4.6838e-08, 2.3524e-10, 1.8004e-07, 9.1439e-08, 7.1145e-06, 5.3764e-12,\n",
              "         1.7780e-09, 2.8106e-13, 1.2200e-07],\n",
              "        [9.7229e-01, 7.1995e-11, 1.9053e-02, 7.9522e-11, 3.5196e-07, 5.5519e-12,\n",
              "         1.0603e-07, 5.1595e-10, 3.7342e-08, 1.0876e-06, 7.8724e-09, 2.7561e-08,\n",
              "         1.5530e-09, 3.7244e-13, 1.2854e-06, 4.6879e-09, 1.8886e-07, 2.1766e-07,\n",
              "         7.7725e-03, 2.3715e-07, 3.3227e-06, 3.0662e-07, 8.7141e-04, 3.2496e-09,\n",
              "         9.2878e-08, 2.8768e-10, 2.0533e-06],\n",
              "        [1.1993e-01, 9.1425e-06, 1.1699e-03, 7.8371e-11, 2.8627e-11, 2.5420e-02,\n",
              "         1.6505e-05, 8.7227e-03, 3.7508e-04, 1.8766e-06, 3.2138e-03, 2.9004e-08,\n",
              "         2.0683e-05, 3.6655e-10, 3.5563e-07, 1.8826e-05, 1.7953e-03, 2.8177e-09,\n",
              "         1.4266e-03, 1.0805e-07, 3.0879e-05, 1.0411e-07, 8.3781e-01, 7.8822e-06,\n",
              "         3.4476e-05, 1.0984e-10, 8.7422e-08],\n",
              "        [4.6757e-01, 1.3312e-09, 4.6563e-04, 9.4910e-09, 2.4747e-08, 4.0073e-05,\n",
              "         1.9258e-05, 8.3495e-06, 1.8158e-05, 4.0776e-06, 5.2980e-01, 9.6776e-08,\n",
              "         1.7462e-06, 7.5673e-15, 1.7748e-06, 2.1630e-08, 8.3166e-10, 1.3997e-07,\n",
              "         8.5922e-04, 1.1718e-10, 4.1996e-05, 2.5073e-10, 1.1575e-03, 5.3174e-06,\n",
              "         1.0973e-07, 1.1988e-10, 6.7365e-07],\n",
              "        [8.4091e-01, 1.2289e-08, 2.2634e-04, 4.4767e-11, 7.8881e-07, 1.1598e-09,\n",
              "         9.5910e-05, 5.7258e-07, 8.2537e-07, 2.6620e-04, 1.1934e-04, 2.7519e-05,\n",
              "         2.1730e-09, 1.8216e-12, 1.4559e-05, 6.7146e-09, 1.5744e-05, 3.1753e-09,\n",
              "         1.5696e-01, 4.9077e-06, 2.9588e-07, 2.2518e-05, 1.3299e-03, 4.5826e-06,\n",
              "         1.5175e-06, 2.2540e-07, 1.5299e-07],\n",
              "        [3.3106e-03, 9.7189e-11, 1.2545e-03, 3.1538e-09, 6.5531e-09, 4.5975e-06,\n",
              "         2.0346e-06, 2.2117e-05, 8.0628e-09, 6.0655e-05, 1.7605e-08, 6.7145e-11,\n",
              "         9.3937e-08, 1.4065e-05, 5.9422e-06, 2.4952e-02, 6.9767e-04, 3.8198e-06,\n",
              "         3.2406e-06, 6.6249e-07, 3.8148e-03, 6.1489e-06, 9.6269e-01, 2.4417e-09,\n",
              "         1.7452e-07, 2.8327e-09, 3.1520e-03],\n",
              "        [1.5722e-05, 1.3911e-04, 3.0836e-04, 4.7817e-07, 6.8884e-07, 1.9844e-07,\n",
              "         1.1192e-06, 6.5558e-06, 2.9798e-13, 6.0679e-06, 2.1486e-10, 1.2604e-03,\n",
              "         1.8259e-07, 4.4710e-10, 3.2517e-08, 2.8199e-09, 2.9736e-07, 9.5218e-01,\n",
              "         4.5802e-02, 1.7763e-10, 3.9073e-06, 3.2788e-07, 9.1368e-05, 9.9143e-06,\n",
              "         3.4173e-13, 1.1125e-06, 1.6985e-04],\n",
              "        [9.5684e-06, 1.0281e-05, 1.8907e-03, 2.6177e-10, 5.2607e-04, 9.6738e-08,\n",
              "         9.5320e-02, 5.4292e-07, 5.5135e-06, 5.9975e-12, 2.9860e-05, 1.8521e-08,\n",
              "         3.8003e-05, 7.0496e-01, 2.0971e-05, 6.1511e-07, 1.7263e-01, 3.6126e-07,\n",
              "         1.3873e-04, 8.3771e-04, 5.8673e-04, 6.3772e-03, 1.5245e-02, 6.9621e-12,\n",
              "         2.2088e-04, 1.0572e-03, 8.8580e-05],\n",
              "        [2.0399e-04, 2.3554e-10, 1.4319e-02, 8.5613e-08, 3.7989e-15, 1.6559e-08,\n",
              "         4.4548e-06, 8.6983e-12, 3.1950e-16, 2.6955e-09, 4.5600e-13, 9.8067e-09,\n",
              "         9.2971e-12, 1.1067e-13, 4.2840e-09, 4.7317e-08, 9.5280e-10, 9.8534e-01,\n",
              "         1.1880e-11, 1.7098e-10, 3.7957e-05, 6.8626e-09, 9.5768e-05, 4.3628e-11,\n",
              "         8.5074e-11, 7.0619e-13, 4.6019e-07]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NbEwXgdmYE4",
        "outputId": "1da1b181-6110-472a-b19c-e4f791f4418a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZGAJRwQniU1",
        "outputId": "36c42893-ed9b-434b-fcda-c730da1dd934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob[torch.arange(32), Y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-ado0BRnmk5",
        "outputId": "a658a9ba-51dc-4b7c-ddce-97ea5c3d30ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5420e-02, 2.6097e-13, 1.0202e-04, 7.8527e-08, 2.1250e-12, 1.8826e-05,\n",
              "        7.5376e-05, 5.0993e-05, 9.9372e-01, 4.9808e-08, 6.4269e-06, 2.3799e-15,\n",
              "        9.1425e-06, 5.3728e-01, 1.5516e-12, 4.7916e-06, 1.8766e-06, 2.8884e-07,\n",
              "        5.8920e-05, 4.8498e-03, 5.6223e-09, 1.1571e-12, 1.0129e-06, 9.1994e-14,\n",
              "        9.7229e-01, 1.0805e-07, 2.1630e-08, 1.5744e-05, 8.0628e-09, 6.0679e-06,\n",
              "        1.0281e-05, 2.0399e-04])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-prob[torch.arange(32), Y].log().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMXbHAwKoF_H",
        "outputId": "4f2bb391-4679-4760-ea14-7a5894da59a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.7704)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator = g)\n",
        "W1 = torch.randn((6,100), generator = g)\n",
        "b1 = torch.randn(100 , generator = g)\n",
        "W2 = torch.randn((100,27), generator = g)\n",
        "b2 = torch.randn(27 , generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "RknrpnhDoKkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # total number of params in our model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fqAp_4do47r",
        "outputId": "d603a9e4-4d32-46d5-cf35-c9b3fe173485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "prob = logits.exp() / logits.exp().sum(1, keepdims = True)\n",
        "loss = -prob[torch.arange(32), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH3ixb-Io5t7",
        "outputId": "22ec7404-38b0-436c-b73c-04c6cd7aae00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.7697)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v--5Mye1rT0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1abe61-c489-4f37-be78-cbe0660df055",
        "id": "M4yy1fn2rWV_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.7697)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator = g)\n",
        "W1 = torch.randn((6,100), generator = g)\n",
        "b1 = torch.randn(100 , generator = g)\n",
        "W2 = torch.randn((100,27), generator = g)\n",
        "b2 = torch.randn(27 , generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "WFz-1MUlo_uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # total number of params in our model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SypQJmPvpFkz",
        "outputId": "b164ba31-760e-443b-de78-e497b5f2bd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "MLLHlHD7pQyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(100):\n",
        "    # forward pass\n",
        "    emb = C[X]\n",
        "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Y)\n",
        "    print(loss.item())\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.1 * p.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XutP2fQVpa17",
        "outputId": "972db281-c682-43ad-d444-15ddbd77edec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2789476215839386\n",
            "0.27876269817352295\n",
            "0.27858036756515503\n",
            "0.2784004509449005\n",
            "0.2782229483127594\n",
            "0.2780477702617645\n",
            "0.27787497639656067\n",
            "0.27770447731018066\n",
            "0.2775361239910126\n",
            "0.27737003564834595\n",
            "0.2772060036659241\n",
            "0.2770441174507141\n",
            "0.2768843173980713\n",
            "0.27672645449638367\n",
            "0.2765706479549408\n",
            "0.2764166593551636\n",
            "0.2762646973133087\n",
            "0.2761145234107971\n",
            "0.27596622705459595\n",
            "0.27581968903541565\n",
            "0.2756749987602234\n",
            "0.27553197741508484\n",
            "0.2753906548023224\n",
            "0.27525097131729126\n",
            "0.27511295676231384\n",
            "0.27497658133506775\n",
            "0.2748417556285858\n",
            "0.27470850944519043\n",
            "0.2745767831802368\n",
            "0.274446576833725\n",
            "0.27431780099868774\n",
            "0.2741905152797699\n",
            "0.2740646004676819\n",
            "0.2739401161670685\n",
            "0.2738170027732849\n",
            "0.2736952602863312\n",
            "0.2735748291015625\n",
            "0.27345576882362366\n",
            "0.27333787083625793\n",
            "0.27322134375572205\n",
            "0.2731059789657593\n",
            "0.27299192547798157\n",
            "0.27287906408309937\n",
            "0.2727673351764679\n",
            "0.27265676856040955\n",
            "0.2725474238395691\n",
            "0.2724391520023346\n",
            "0.2723320424556732\n",
            "0.2722259759902954\n",
            "0.27212101221084595\n",
            "0.27201706171035767\n",
            "0.2719142436981201\n",
            "0.27181243896484375\n",
            "0.2717116177082062\n",
            "0.271611750125885\n",
            "0.271512895822525\n",
            "0.2714150547981262\n",
            "0.27131813764572144\n",
            "0.27122220396995544\n",
            "0.2711271643638611\n",
            "0.27103298902511597\n",
            "0.27093976736068726\n",
            "0.2708474397659302\n",
            "0.27075597643852234\n",
            "0.27066534757614136\n",
            "0.2705756425857544\n",
            "0.27048665285110474\n",
            "0.2703985869884491\n",
            "0.27031129598617554\n",
            "0.27022483944892883\n",
            "0.2701391577720642\n",
            "0.2700542211532593\n",
            "0.2699700891971588\n",
            "0.26988673210144043\n",
            "0.26980409026145935\n",
            "0.26972222328186035\n",
            "0.2696409821510315\n",
            "0.2695606052875519\n",
            "0.26948082447052\n",
            "0.26940181851387024\n",
            "0.2693234980106354\n",
            "0.26924583315849304\n",
            "0.26916879415512085\n",
            "0.26909250020980835\n",
            "0.269016832113266\n",
            "0.26894181966781616\n",
            "0.2688674330711365\n",
            "0.26879364252090454\n",
            "0.26872050762176514\n",
            "0.26864802837371826\n",
            "0.26857608556747437\n",
            "0.268504798412323\n",
            "0.2684340476989746\n",
            "0.26836392283439636\n",
            "0.2682943642139435\n",
            "0.26822540163993835\n",
            "0.2681569755077362\n",
            "0.26808908581733704\n",
            "0.26802170276641846\n",
            "0.26795494556427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we are just talking about 5 words and 32 examples"
      ],
      "metadata": {
        "id": "WiK_VpO6phWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyDKR49qpi0g",
        "outputId": "eb210eca-ef24-478c-e50f-c7b7904436b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([12.2507, 15.6167, 19.7251, 19.2065, 15.1653, 12.2507, 14.5368, 12.9834,\n",
              "        14.6929, 16.7506, 14.3019, 19.3470, 12.2507, 15.2280, 15.6323, 18.4261,\n",
              "        12.2507, 15.1299, 13.3647, 15.2784, 17.2229, 14.2677,  9.4187,  9.3573,\n",
              "        14.6208, 12.2507, 14.8763, 15.4997, 11.8749, 15.2119, 17.4153, 14.0490],\n",
              "       grad_fn=<MaxBackward0>),\n",
              "indices=tensor([19, 13, 13,  1,  0, 19, 12,  9, 22,  9,  1,  0, 19, 22,  1,  0, 19, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac2lk3IJprF0",
        "outputId": "b730000c-1784-4176-e829-e059311502bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3\n",
        "X, Y = [], []\n",
        "for w in words:\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "        context = context[1:] + [ix] # crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "t7il8DgZpsD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEmzRueLxTMX",
        "outputId": "e92050f4-44f8-4085-967d-4dff09ec894c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 3]), torch.Size([228146]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator = g)\n",
        "W1 = torch.randn((6,100), generator = g)\n",
        "b1 = torch.randn(100 , generator = g)\n",
        "W2 = torch.randn((100,27), generator = g)\n",
        "b2 = torch.randn(27 , generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "ISajrCLops2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # total number of params in our model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDzLGavWpwaG",
        "outputId": "bcfc1f2f-eaaa-4620-e648-d8185cbbd5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "bz7fbqesp0vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "SE0fO7_5p4yX",
        "outputId": "86a045ca-cb07-41eb-8bc1-ce5f07ba0f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.505229949951172\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-615019508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(100):\n",
        "    # forward pass\n",
        "    emb = C[X]\n",
        "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Y)\n",
        "    print(loss.item())\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.1 * p.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3120d88b-a669-4171-8332-f28e1275f4d1",
        "id": "jQVqSNj3yvr6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.803146839141846\n",
            "5.722784042358398\n",
            "5.64509391784668\n",
            "5.5699462890625\n",
            "5.497213840484619\n",
            "5.4267802238464355\n",
            "5.3585357666015625\n",
            "5.2923760414123535\n",
            "5.228203773498535\n",
            "5.165928363800049\n",
            "5.105468273162842\n",
            "5.04674768447876\n",
            "4.98969841003418\n",
            "4.934261322021484\n",
            "4.880379676818848\n",
            "4.828005313873291\n",
            "4.777095794677734\n",
            "4.727609157562256\n",
            "4.679513931274414\n",
            "4.632779121398926\n",
            "4.587378025054932\n",
            "4.543288707733154\n",
            "4.500490665435791\n",
            "4.4589667320251465\n",
            "4.418700218200684\n",
            "4.379675388336182\n",
            "4.3418779373168945\n",
            "4.305292129516602\n",
            "4.269898891448975\n",
            "4.235679626464844\n",
            "4.202611923217773\n",
            "4.170670032501221\n",
            "4.139823913574219\n",
            "4.110044002532959\n",
            "4.081292152404785\n",
            "4.053531169891357\n",
            "4.02672004699707\n",
            "4.00081729888916\n",
            "3.9757795333862305\n",
            "3.951563596725464\n",
            "3.9281277656555176\n",
            "3.905430793762207\n",
            "3.8834331035614014\n",
            "3.862098217010498\n",
            "3.84139084815979\n",
            "3.821279764175415\n",
            "3.8017334938049316\n",
            "3.782726287841797\n",
            "3.764232635498047\n",
            "3.7462291717529297\n",
            "3.7286949157714844\n",
            "3.7116103172302246\n",
            "3.6949586868286133\n",
            "3.678722381591797\n",
            "3.662886381149292\n",
            "3.64743709564209\n",
            "3.6323606967926025\n",
            "3.617644786834717\n",
            "3.6032779216766357\n",
            "3.5892493724823\n",
            "3.5755467414855957\n",
            "3.562162160873413\n",
            "3.549083948135376\n",
            "3.5363047122955322\n",
            "3.5238137245178223\n",
            "3.5116031169891357\n",
            "3.499664068222046\n",
            "3.4879894256591797\n",
            "3.476569890975952\n",
            "3.4653983116149902\n",
            "3.454468011856079\n",
            "3.44377064704895\n",
            "3.433300018310547\n",
            "3.4230494499206543\n",
            "3.4130117893218994\n",
            "3.403181314468384\n",
            "3.39355206489563\n",
            "3.3841164112091064\n",
            "3.374871253967285\n",
            "3.365809440612793\n",
            "3.356926202774048\n",
            "3.3482167720794678\n",
            "3.339675188064575\n",
            "3.331298589706421\n",
            "3.3230807781219482\n",
            "3.3150179386138916\n",
            "3.3071060180664062\n",
            "3.2993407249450684\n",
            "3.291717529296875\n",
            "3.284233808517456\n",
            "3.2768850326538086\n",
            "3.269667387008667\n",
            "3.262578248977661\n",
            "3.2556138038635254\n",
            "3.248770236968994\n",
            "3.2420454025268555\n",
            "3.2354345321655273\n",
            "3.2289366722106934\n",
            "3.2225475311279297\n",
            "3.216263771057129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it will take a bit of time for each iteration"
      ],
      "metadata": {
        "id": "mqHdviQUxvOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn1SKCMxzLCk",
        "outputId": "0ca402a6-6d26-4f4a-fde7-dbb6e42b2dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(0,5,(32,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFkrlzLazLwM",
        "outputId": "2c6f4031-2877-4365-c5d8-c4588121dbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 0, 3, 4, 2, 4, 1, 1, 4, 0, 0, 2, 4, 0, 0, 1, 1, 3, 2, 1, 3, 3, 0,\n",
              "        4, 2, 3, 3, 0, 3, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X[ix]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omF7QfG1zXMn",
        "outputId": "a4b29b85-b53b-4da4-fd6e-160c0cc74a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4216,  2.1558],\n",
              "         [ 0.4216,  2.1558],\n",
              "         [-0.0497, -0.3762]],\n",
              "\n",
              "        [[-0.5696, -0.0213],\n",
              "         [-0.6086,  0.0470],\n",
              "         [-0.0497, -0.3762]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 1.1269, -0.6584]],\n",
              "\n",
              "        [[-0.5696, -0.0213],\n",
              "         [-0.6086,  0.0470],\n",
              "         [ 0.0873, -0.4394]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [-0.6957, -0.8288],\n",
              "         [ 0.4824,  2.1639]],\n",
              "\n",
              "        [[-0.0363, -0.3810],\n",
              "         [-0.4991, -0.0838],\n",
              "         [-0.6086,  0.0470]],\n",
              "\n",
              "        [[-0.6086,  0.0470],\n",
              "         [-0.6086,  0.0470],\n",
              "         [-0.0497, -0.3762]],\n",
              "\n",
              "        [[ 0.0873, -0.4394],\n",
              "         [-0.0363, -0.3810],\n",
              "         [-0.4963, -0.0514]],\n",
              "\n",
              "        [[-0.6086,  0.0470],\n",
              "         [-0.0497, -0.3762],\n",
              "         [-0.1314, -0.4111]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.8065, -0.4813]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[-0.0623, -0.2842],\n",
              "         [-0.0363, -0.3810],\n",
              "         [-0.0363, -0.3810]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.0676, -0.5056]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.4216,  2.1558]],\n",
              "\n",
              "        [[ 0.0873, -0.4394],\n",
              "         [ 1.1269, -0.6584],\n",
              "         [ 0.0873, -0.4394]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [-0.7804,  0.1302],\n",
              "         [ 0.5174, -0.6004]],\n",
              "\n",
              "        [[ 0.0676, -0.5056],\n",
              "         [-0.5696, -0.0213],\n",
              "         [-0.6086,  0.0470]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.0085, -0.4978],\n",
              "         [ 0.0873, -0.4394]],\n",
              "\n",
              "        [[ 0.0676, -0.5056],\n",
              "         [-0.5696, -0.0213],\n",
              "         [-0.6086,  0.0470]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [-0.0623, -0.2842]],\n",
              "\n",
              "        [[ 0.0085, -0.4978],\n",
              "         [-0.0497, -0.3762],\n",
              "         [-0.4991, -0.0838]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[-0.6086,  0.0470],\n",
              "         [-0.0497, -0.3762],\n",
              "         [-0.0363, -0.3810]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[ 0.0873, -0.4394],\n",
              "         [-0.4963, -0.0514],\n",
              "         [ 0.4216,  2.1558]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498],\n",
              "         [ 0.6119, -0.4498]],\n",
              "\n",
              "        [[ 0.6119, -0.4498],\n",
              "         [-0.4963, -0.0514],\n",
              "         [-0.0497, -0.3762]]], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(0,X.shape[0],(32,))\n",
        "ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux73JCcOzPMc",
        "outputId": "20d1d2d5-99b7-4368-a1e7-030ee1211fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([134769, 144844,  67732,  78212, 224927, 158487, 120421, 175080,  41728,\n",
              "         19708, 223992, 113349, 105881, 196089,  32317, 188719, 193024,  94020,\n",
              "        226207, 128930, 155645,  23443, 154352,  37162, 114125, 155194,  22464,\n",
              "         27565,  31664,  59863, 201293,  38038])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for _ in range(10):\n",
        "for _ in range(1000):\n",
        "    # mini batch construction\n",
        "    ix = torch.randint(0,X.shape[0],(32,))\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[X[ix]]\n",
        "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Y[ix])\n",
        "    #print(loss.item())\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.00001 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq8nACwhzhW1",
        "outputId": "82a09dbc-1ca7-45b4-9a0f-4f40cb3332d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.330946922302246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since we are doing mini batches, the quality of our gradient is lower\n",
        "# its better to have approx gradient and take more steps\n",
        "# rather than to evaluate exact gradient and take fewer steps"
      ],
      "metadata": {
        "id": "oPGfRiP2zqSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBa8H4nl1AT0",
        "outputId": "fd162fc2-df56-48fb-8075-f817a209e05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.1985, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this model is very small with close to 3k params, models can have millions or billions of param\n",
        "# as the capacity of the neural network grows, it becomes more and more capable of overfitting the training set\n",
        "# the loss on training set might become close to 0 and all what model is doing is memorizing all the examples it saw\n",
        "# when we sample we get same names as the training set\n",
        "# split the dataset into 3 splits (training, val/dev, test)\n",
        "# 80% , 10%, 10%"
      ],
      "metadata": {
        "id": "ll3Yeahz1xOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBbuWY7d189m",
        "outputId": "dbc0cab3-6725-4b2c-a1ec-a89b572a7746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator = g)\n",
        "W1 = torch.randn((6,100), generator = g)\n",
        "b1 = torch.randn(100 , generator = g)\n",
        "W2 = torch.randn((100,27), generator = g)\n",
        "b2 = torch.randn(27 , generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "EZ2NKASd2BWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # total number of params in our model"
      ],
      "metadata": {
        "id": "y_wb1Jch2LcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "sG57Gx2g2PPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10000):\n",
        "\n",
        "    # mini batch construction\n",
        "    ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xtr[ix]]\n",
        "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.01 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "BVWfOJYC2TfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr]\n",
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss"
      ],
      "metadata": {
        "id": "xq9PDKMl2eJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xdev]\n",
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss"
      ],
      "metadata": {
        "id": "aXnBStmj2fgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the loss on full training data and dev data are almost same, we are not overfitting.\n",
        "# this model is not powerful enough to memorize things.\n",
        "# that means our network is small, we can expect to make improvements by scaling up the size."
      ],
      "metadata": {
        "id": "XubBp2_-32sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hidden layer bias 300\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator = g)\n",
        "W1 = torch.randn((6,300), generator = g)\n",
        "b1 = torch.randn(300 , generator = g)\n",
        "W2 = torch.randn((300,27), generator = g)\n",
        "b2 = torch.randn(27 , generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "4LQ2N2Ak38ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # total number of params in our model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5rW-OKA4Awe",
        "outputId": "e56ff5f5-65d3-46a7-e205-9c3d5f48a97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10281"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "2bQIdAhV5C3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10000):\n",
        "\n",
        "    # mini batch construction\n",
        "    ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xtr[ix]]\n",
        "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.001 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4cGvalW5KTc",
        "outputId": "7a9e097e-ece7-40f9-d3f7-7e133658a308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4627015590667725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr]\n",
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl5xNUmR5UhT",
        "outputId": "ddeb7282-8c83-49b8-a022-bbb40aa686f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5742, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xdev]\n",
        "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlmU0AZp5d8W",
        "outputId": "1b04bd05-7546-4327-bf41-a5c1343ded6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5618, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IApCz7xk5nOo",
        "outputId": "6009b2e8-28ff-4164-d089-38ac0e283378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "careah.\n",
            "aal.\n",
            "hlvihkimli.\n",
            "reaty.\n",
            "halassne.\n",
            "rahnen.\n",
            "amerart.\n",
            "kaqui.\n",
            "nelonia.\n",
            "ceriiv.\n",
            "kale.\n",
            "gve.\n",
            "bman.\n",
            "cadesinn.\n",
            "sroilea.\n",
            "jamii.\n",
            "wazero.\n",
            "dearyni.\n",
            "jameeniusdt.\n",
            "edae.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since we have the embedding of 2, it might be a bottleneck"
      ],
      "metadata": {
        "id": "cuXo_6KC5sP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dimensions 0 and 1 of the embedding matrix C for all characters\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
        "for i in range(C.shape[0]):\n",
        "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
        "plt.grid('minor')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-cABv0C95tvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,10), generator = g)\n",
        "W1 = torch.randn((30,300), generator = g)\n",
        "b1 = torch.randn(300 , generator = g)\n",
        "W2 = torch.randn((300,27), generator = g)\n",
        "b2 = torch.randn(27 , generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "RTAMGcir5_PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # total number of params in our model"
      ],
      "metadata": {
        "id": "vOjMw2tD6Baa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "asrU4I746E66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10000):\n",
        "\n",
        "    # mini batch construction\n",
        "    ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xtr[ix]]\n",
        "    h = torch.tanh(emb.view(-1,30) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.01 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "GPiNqVtp6JsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr]\n",
        "h = torch.tanh(emb.view(-1,30) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss"
      ],
      "metadata": {
        "id": "Hapqv5dp6R7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xdev]\n",
        "h = torch.tanh(emb.view(-1,30) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss"
      ],
      "metadata": {
        "id": "BeWZG0Yt6V3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,100), generator = g)\n",
        "W1 = torch.randn((300,500), generator = g)\n",
        "b1 = torch.randn(500 , generator = g)\n",
        "W2 = torch.randn((500,27), generator = g)\n",
        "b2 = torch.randn(27 , generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "A6pBUM5Z6ZSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # total number of params in our model"
      ],
      "metadata": {
        "id": "158QIZDH6d8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "oWGZ7__s6iKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10000):\n",
        "\n",
        "    # mini batch construction\n",
        "    ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xtr[ix]]\n",
        "    h = torch.tanh(emb.view(-1,300) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.001 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "1PD6hikK6lui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr]\n",
        "h = torch.tanh(emb.view(-1,300) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss"
      ],
      "metadata": {
        "id": "KLW_JHae6rdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xdev]\n",
        "h = torch.tanh(emb.view(-1,300) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss"
      ],
      "metadata": {
        "id": "ppFGRoUI6wjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "id": "f5zHUAYZ6z9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}